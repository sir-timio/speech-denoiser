{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0771362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8716b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../wave_wizard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26c6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import get_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497e50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "SECS = 11\n",
    "length=SR*SECS\n",
    "sample_rate=22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2abc3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict({\n",
    "    'dataset': {\n",
    "        'json_dir': '../dataset/',\n",
    "        'length': SR*SECS,\n",
    "        'sample_rate': SR,\n",
    "        'num_samples': 10_000,\n",
    "\n",
    "    },\n",
    "    'dataloader': {\n",
    "        'batch_size': 64,\n",
    "    }\n",
    "})\n",
    "num_samples = config['dataset'].pop('num_samples')\n",
    "num_samples = config['dataset'].pop('a', None)\n",
    "loader = get_loader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ac76d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449182"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf4b2d",
   "metadata": {},
   "source": [
    "# Basic Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66db56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=True,\n",
    "                 activation=nn.PReLU()):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride, padding=padding,\n",
    "            bias=bias\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.activation = activation\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cc79ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDeConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=True,\n",
    "                 activation=nn.PReLU()):\n",
    "        super(BasicDeConv, self).__init__()\n",
    "        self.deconv = nn.ConvTranspose1d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride, padding=padding,\n",
    "            bias=bias\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.activation = activation\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04e944",
   "metadata": {},
   "source": [
    "# Gated Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17d0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedConv(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=3, stride=1, padding=1,\n",
    "                dilation=1, groups=1, bias=True,\n",
    "                batch_norm=True,\n",
    "                activation=nn.LeakyReLU(0.2, inplace=True)):\n",
    "        super(GatedConv, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        self.conv = nn.Conv1d(\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding,\n",
    "            \n",
    "                bias=bias\n",
    "            )\n",
    "        self.mask_conv = nn.Conv1d(\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding,\n",
    "                bias=bias\n",
    "            )\n",
    "        self.batch_norm = nn.BatchNorm1d(out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "    \n",
    "    def gated(self, mask):\n",
    "        return self.sigmoid(mask)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        mask = self.mask_conv(input)\n",
    "        x = x * self.gated(mask)\n",
    "        x = self.batch_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc9441c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedDeConv(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=3, stride=1, padding=1,\n",
    "                dilation=1, groups=1, bias=True,\n",
    "                batch_norm=True,\n",
    "                activation=nn.LeakyReLU(0.2, inplace=True)):\n",
    "        super(GatedDeConv, self).__init__()\n",
    "        self.batch_norm = batch_norm\n",
    "        self.activation = activation\n",
    "        self.deconv = nn.ConvTranspose1d(\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding,\n",
    "                bias=bias\n",
    "            )\n",
    "        self.mask_deconv = nn.ConvTranspose1d(\n",
    "                in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding,\n",
    "                bias=bias\n",
    "            )\n",
    "        self.batch_norm = nn.BatchNorm1d(out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose1d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "    \n",
    "    def gated(self, mask):\n",
    "        return self.sigmoid(mask)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.deconv(input)\n",
    "        mask = self.mask_deconv(input)\n",
    "        x = x * self.gated(mask)\n",
    "        x = self.batch_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04af6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for noisy, clean in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c0229af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class GateWave(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=3, scale=2, init_hidden=32,\n",
    "                 kernel_size=7, stride=1, padding=2,\n",
    "                 encoder_class=BasicConv,\n",
    "                 decoder_class=BasicDeConv):\n",
    "        super(GateWave, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        in_channels = 1\n",
    "        out_channels = 1\n",
    "        encoders = []\n",
    "        decoders = []\n",
    "        \n",
    "        hidden = init_hidden\n",
    "        in_ch = in_channels\n",
    "        for i in range(depth):\n",
    "            \n",
    "            encoder = encoder_class(in_channels, hidden, kernel_size, stride, padding)\n",
    "            encoders.append(encoder)\n",
    "            \n",
    "            decoder = decoder_class(hidden, out_channels, kernel_size, stride, padding)\n",
    "            decoders.append(decoder)\n",
    "            out_channels = hidden\n",
    "            in_channels = hidden\n",
    "            hidden = int(hidden * scale)\n",
    "            \n",
    "            \n",
    "        self.encoder = nn.Sequential(*encoders)\n",
    "        self.decoder = nn.Sequential(*decoders[::-1])\n",
    "    \n",
    "    def valid_length(self, length):\n",
    "        \"\"\"\n",
    "        Return the nearest valid length to use with the model so that\n",
    "        there is no time steps left over in a convolutions, e.g. for all\n",
    "        layers, size of the input - kernel_size % stride = 0.\n",
    "        If the mixture has a valid length, the estimated sources\n",
    "        will have exactly the same length.\n",
    "        \"\"\"\n",
    "#         length = math.ceil(length * self.resample)\n",
    "        for idx in range(self.depth):\n",
    "            length = math.ceil((length - self.kernel_size) / self.stride) + 1\n",
    "            length = max(length, 1)\n",
    "        for idx in range(self.depth):\n",
    "            length = (length - 1) * self.stride + self.kernel_size\n",
    "#         length = int(math.ceil(length / self.resample))\n",
    "        return int(length)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        length = x.shape[-1]\n",
    "        x = F.pad(x, (0, self.valid_length(length) - length))\n",
    "        latent = self.encoder(x)\n",
    "        output = self.decoder(latent)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bd3c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GateWave(encoder_class=GatedConv, decoder_class=GatedDeConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4922603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd291cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "114082a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for noisy, clean in loader:\n",
    "    pred = model(noisy)\n",
    "    l = loss(clean, pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aee9406b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2287, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ad211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47dcd213",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = STFTLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ced69213",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stft(torch.FloatTensor[32, 1, 243574], n_fft=1024, hop_length=120, win_length=600, window=torch.FloatTensor{[600]}, normalized=0, onesided=None, return_complex=1) : expected a 1D or 2D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/audio/denoiser/pybooks/../wave_wizard/src/loss.py:84\u001b[0m, in \u001b[0;36mSTFTLoss.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124;03m\"\"\"Calculate forward propagation.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        x (Tensor): Predicted signal (B, T).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m        Tensor: Log STFT magnitude loss value.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     x_mag \u001b[38;5;241m=\u001b[39m \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     y_mag \u001b[38;5;241m=\u001b[39m stft(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfft_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshift_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow)\n\u001b[1;32m     86\u001b[0m     sc_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspectral_convergenge_loss(x_mag, y_mag)\n",
      "File \u001b[0;32m~/workspace/audio/denoiser/pybooks/../wave_wizard/src/loss.py:18\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(x, fft_size, hop_size, win_length, window)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstft\u001b[39m(x, fft_size, hop_size, win_length, window):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform STFT and convert to magnitude spectrogram.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        x (Tensor): Input signal tensor (B, T).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        Tensor: Magnitude spectrogram (B, #frames, fft_size // 2 + 1).\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     x_stft \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfft_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m     real \u001b[38;5;241m=\u001b[39m x_stft[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m     imag \u001b[38;5;241m=\u001b[39m x_stft[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/py/lib/python3.9/site-packages/torch/functional.py:641\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(extended_shape), [pad, pad], pad_mode)\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39msignal_dim:])\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m    642\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stft(torch.FloatTensor[32, 1, 243574], n_fft=1024, hop_length=120, win_length=600, window=torch.FloatTensor{[600]}, normalized=0, onesided=None, return_complex=1) : expected a 1D or 2D tensor"
     ]
    }
   ],
   "source": [
    "loss(clean, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a1679a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=3\n",
    "scale=2\n",
    "hidden=32\n",
    "kernel_size=7\n",
    "stride=1\n",
    "padding=2\n",
    "encoder_class=BasicConv\n",
    "decoder_class=BasicDeConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa081041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channels = 1\n",
    "# out_channels = 1\n",
    "# encoders = []\n",
    "# decoders = []\n",
    "\n",
    "# in_ch = in_channels\n",
    "# for i in range(depth):\n",
    "\n",
    "#     encoder = encoder_class(in_channels, hidden, kernel_size, stride, padding)\n",
    "#     encoders.append(encoder)\n",
    "\n",
    "#     decoder = decoder_class(hidden, out_channels, kernel_size, stride, padding)\n",
    "#     decoders.append(decoder)\n",
    "#     out_channels = hidden\n",
    "#     in_channels = hidden\n",
    "#     hidden *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d5da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
